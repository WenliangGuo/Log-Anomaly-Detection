{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import dataloader\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 575061 instances, 14468 anomaly, 560593 normal\n",
      "Train: 362288 instances, 11762 anomaly, 350526 normal\n",
      "Validation: 40254 instances, 1353 anomaly, 38901 normal\n",
      "Test: 172519 instances, 1353 anomaly, 171166 normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_path = 'logs/HDFS/structured/HDFS.log_structured.csv'\n",
    "label_path = 'logs/HDFS/anomaly_label.csv'\n",
    "template_path = 'logs/HDFS/structured/HDFS.log_templates.csv'\n",
    "\n",
    "x_train, y_train, x_test, y_test = dataloader.load_HDFS(\n",
    "    log_file = log_path, \n",
    "    label_file = label_path, \n",
    "    template_file = template_path,\n",
    "    train_ratio=0.7,\n",
    "    save_csv=False)\n",
    "\n",
    "\n",
    "num_val = x_train.shape[0] // 10\n",
    "num_train = x_train.shape[0] - num_val\n",
    "\n",
    "x_val = x_train[:num_val]\n",
    "y_val = y_train[:num_val]\n",
    "x_train = x_train[num_val:]\n",
    "y_train = y_train[num_val:]\n",
    "\n",
    "num_test = x_test.shape[0]\n",
    "num_total = num_train + num_val + num_test \n",
    "\n",
    "num_train_pos = sum(y_train)\n",
    "num_val_pos = sum(y_val)\n",
    "num_test_pos = sum(y_val)\n",
    "num_pos = num_train_pos + num_val_pos + num_test_pos\n",
    "\n",
    "print('Total: {} instances, {} anomaly, {} normal' \\\n",
    "      .format(num_total, num_pos, num_total - num_pos))\n",
    "print('Train: {} instances, {} anomaly, {} normal' \\\n",
    "      .format(num_train, num_train_pos, num_train - num_train_pos))\n",
    "print('Validation: {} instances, {} anomaly, {} normal' \\\n",
    "      .format(num_val, num_val_pos, num_val - num_val_pos))\n",
    "print('Test: {} instances, {} anomaly, {} normal\\n' \\\n",
    "      .format(num_test, num_test_pos, num_test - num_test_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 128\n",
    "lr= 0.001\n",
    "num_epochs= 20\n",
    "max_length = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_tensor = torch.Tensor(x_train[:2000])\n",
    "y_train_tensor = torch.Tensor(y_train[:2000]).to(torch.int64)\n",
    "y_train_tensor = F.one_hot(y_train_tensor, num_classes = 2)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor,y_train_tensor.to(torch.float))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True) \n",
    "\n",
    "x_val_tensor = torch.Tensor(x_val[:200])\n",
    "y_val_tensor = torch.Tensor(y_val[:200]).to(torch.int64)\n",
    "y_val_tensor = F.one_hot(y_val_tensor, num_classes = 2)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor,y_val_tensor.to(torch.float))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    Transformer(\n",
    "        in_dim= 1,\n",
    "        embed_dim= 64, \n",
    "        depth= 6,\n",
    "        heads= 8,\n",
    "        dim_head= 64,\n",
    "        dim_ratio= 2,\n",
    "        dropout= 0.1\n",
    "    ),\n",
    "    nn.Linear(max_length*64, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 2),\n",
    "    nn.Softmax()\n",
    ")\n",
    "\n",
    "model = nn.DataParallel(model) # multi-GPU\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "# Loss and optimizer\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "# Train the model\n",
    "loss_min = 99999\n",
    "model_name = 'best_model.pth'\n",
    "model_path = \"saved_models\"\n",
    "\n",
    "save_path = os.path.join(model_path,model_name)\n",
    "best_model = model\n",
    "train_loss_list = []\n",
    "val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wlguo/miniforge3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "Epoch [1/20], train_loss: 0.65725016593933 val loss: 0.70012092590332\n",
      "Model saved\n",
      "Epoch [2/20], train_loss: 0.41565077565610 val loss: 0.65808597207069\n",
      "Model saved\n",
      "Epoch [3/20], train_loss: 0.37034244649112 val loss: 0.63276532292366\n",
      "Model saved\n",
      "Epoch [4/20], train_loss: 0.36295234039426 val loss: 0.62393811345100\n",
      "Model saved\n",
      "Epoch [5/20], train_loss: 0.36322812922299 val loss: 0.61715680360794\n",
      "Epoch [6/20], train_loss: 0.68629427440464 val loss: 0.70092982053757\n",
      "Epoch [7/20], train_loss: 0.69581278041005 val loss: 0.69004508852959\n",
      "Epoch [8/20], train_loss: 0.68510353937745 val loss: 0.67947977781296\n",
      "Epoch [9/20], train_loss: 0.67494423314929 val loss: 0.66956299543381\n",
      "Epoch [10/20], train_loss: 0.66556967422366 val loss: 0.66093289852142\n",
      "Epoch [11/20], train_loss: 0.65664117038250 val loss: 0.65176650881767\n",
      "Epoch [12/20], train_loss: 0.64816820621490 val loss: 0.64310741424561\n",
      "Epoch [13/20], train_loss: 0.64012734964490 val loss: 0.63619416952133\n",
      "Epoch [14/20], train_loss: 0.63233057036996 val loss: 0.62734490633011\n",
      "Epoch [15/20], train_loss: 0.62492802739143 val loss: 0.62037968635559\n",
      "Model saved\n",
      "Epoch [16/20], train_loss: 0.61772687360644 val loss: 0.61485818028450\n",
      "Model saved\n",
      "Epoch [17/20], train_loss: 0.61083180457354 val loss: 0.60811331868172\n",
      "Model saved\n",
      "Epoch [18/20], train_loss: 0.60385483875871 val loss: 0.60034713149071\n",
      "Model saved\n",
      "Epoch [19/20], train_loss: 0.59744239598513 val loss: 0.59457048773766\n",
      "Model saved\n",
      "Epoch [20/20], train_loss: 0.59123110398650 val loss: 0.58769083023071\n",
      "Finished training, model saved in: saved_models/best_model.pth \n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training ......\")\n",
    "for epoch in range(1, num_epochs+1):  # Loop over the dataset multiple times\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    # Training\n",
    "    for step, (seq, label) in enumerate(train_dataloader):\n",
    "        seq = seq.clone().detach().view(-1, max_length, 1).to(device)\n",
    "        output = model(seq)\n",
    "        loss = criterion(output, label.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ave_trainloss = train_loss / len(train_dataloader)\n",
    "    train_loss_list.append(ave_trainloss)\n",
    "\n",
    "    # Vaildating\n",
    "    with torch.no_grad():    \n",
    "        for step, (seq, label) in enumerate(val_dataloader):\n",
    "            seq = seq.clone().detach().view(-1, max_length, 1).to(device)\n",
    "            output = model(seq)\n",
    "            loss = criterion(output, label.to(device))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    ave_valoss = val_loss / len(val_dataloader)\n",
    "    val_loss_list.append(ave_valoss)\n",
    "\n",
    "    if ave_valoss < loss_min:\n",
    "        loss_min = ave_valoss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        best_model = model\n",
    "        print(\"Model saved\")\n",
    "\n",
    "    print('Epoch [{}/{}], train_loss: {:.14f} val loss: {:.14f}'.format(epoch, num_epochs, ave_trainloss, ave_valoss))\n",
    "\n",
    "print(f\"Finished training, model saved in: {save_path} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7w/r1c9l9r91jz7n4rgggl1ddyh0000gn/T/ipykernel_59433/2692049546.py:7: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "xx = range(num_epochs)\n",
    "plt.plot(xx, train_loss_list, label = \"Train\")\n",
    "plt.plot(xx, val_loss_list, label = \"Val\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"loss.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d371ee047e82898569294ec9a92bd6efded7a8553613c637f3d7c29bad530d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
